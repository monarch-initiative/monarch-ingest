{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Monarch Ingest","text":""},{"location":"#overview","title":"Overview","text":"<p>The Monarch Ingest generates KGX formatted files conforming to the BioLink Model from a wide variety of biomedical data sources.</p> <p>The eventual output of the Monarch Ingest process is the Monarch KG. The latest version of this can be found at data.monarchinitiative.org</p> <p>See also the folder monarch-kg-dev/latest</p> <p>Monarch Ingest is built using Poetry, which will create its own virtual environment. </p>"},{"location":"#installation","title":"Installation","text":"<p>monarch-ingest is a Python 3.8+ package, installable via Poetry.  </p> <ol> <li> <p>Install Poetry, if you don't already have it: <pre><code>curl -sSL https://install.python-poetry.org | python3 -\n\n# Optional: Have poetry create its venvs in your project directories\npoetry config virtualenvs.in-project true\n</code></pre></p> </li> <li> <p>Clone the repo and build the code: <pre><code>git clone git@github.com/monarch-initiative/monarch-ingest\n</code></pre></p> </li> <li> <p>Install monarch-ingest: <pre><code>cd monarch-ingest\npoetry install\n</code></pre></p> </li> <li> <p>(Optional) Activate the virtual environment: <pre><code># This step removes the need to prefix all commands with `poetry run`\npoetry shell\n</code></pre></p> </li> </ol>"},{"location":"#usage","title":"Usage","text":"<p>For a detailed tutorial on ingests and how to make one, see the Create an Ingest tab. </p> <p>CLI usage is available in the CLI tab, gcor by running <code>ingest --help</code>.</p> Run the whole pipeline! <ul> <li> <p>Download the source data: <pre><code>ingest download --all\n</code></pre></p> </li> <li> <p>Run all transforms: <pre><code>ingest transform --all\n</code></pre></p> </li> <li> <p>Merge all transformed output into a tar.gz containing one node and one edge file <pre><code>ingest merge\n</code></pre></p> </li> <li> <p>Upload the results to the Monarch Ingest Google bucket <pre><code>ingest release\n</code></pre></p> </li> </ul> <p> </p>"},{"location":"CLI/","title":"<code>ingest</code>","text":"<p>Usage:</p> <pre><code>$ ingest [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--version</code></li> <li><code>--install-completion</code>: Install completion for the current shell.</li> <li><code>--show-completion</code>: Show completion for the current shell, to copy it or customize the installation.</li> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>closure</code></li> <li><code>download</code>: Downloads data defined in download.yaml</li> <li><code>export</code></li> <li><code>jsonl</code></li> <li><code>merge</code>: Merge nodes and edges into kg</li> <li><code>prepare-release</code></li> <li><code>release</code>: Copy data to Monarch GCP data buckets</li> <li><code>report</code>: Run Koza QC on specified Monarch ingests</li> <li><code>solr</code></li> <li><code>sqlite</code></li> <li><code>transform</code>: Run Koza transformation on specified...</li> </ul>"},{"location":"CLI/#ingest-closure","title":"<code>ingest closure</code>","text":"<p>Usage:</p> <pre><code>$ ingest closure [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"CLI/#ingest-download","title":"<code>ingest download</code>","text":"<p>Downloads data defined in download.yaml</p> <p>Usage:</p> <pre><code>$ ingest download [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>-i, --ingest TEXT</code>: Run a single ingest (see download.yaml for a list)</li> <li><code>--ingests TEXT</code>: Which ingests to download data for</li> <li><code>--all / --no-all</code>: Download all ingest datasets  [default: no-all]</li> <li><code>--write-metadata / --no-write-metadata</code>: Write versions of ingests to metadata.yaml  [default: no-write-metadata]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"CLI/#ingest-export","title":"<code>ingest export</code>","text":"<p>Usage:</p> <pre><code>$ ingest export [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"CLI/#ingest-jsonl","title":"<code>ingest jsonl</code>","text":"<p>Usage:</p> <pre><code>$ ingest jsonl [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"CLI/#ingest-merge","title":"<code>ingest merge</code>","text":"<p>Merge nodes and edges into kg</p> <p>Usage:</p> <pre><code>$ ingest merge [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--input-dir TEXT</code>: Directory with nodes and edges to be merged  [default: output/transform_output]</li> <li><code>--output-dir TEXT</code>: Directory to output data  [default: output]</li> <li><code>-d, --debug / -q, --quiet</code>: Use --quiet to suppress log output, --debug for verbose</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"CLI/#ingest-prepare-release","title":"<code>ingest prepare-release</code>","text":"<p>Usage:</p> <pre><code>$ ingest prepare-release [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"CLI/#ingest-release","title":"<code>ingest release</code>","text":"<p>Copy data to Monarch GCP data buckets</p> <p>Usage:</p> <pre><code>$ ingest release [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--dir TEXT</code>: Directory with kg to be released  [default: output]</li> <li><code>--kghub / --no-kghub</code>: Also release to kghub S3 bucket  [default: no-kghub]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"CLI/#ingest-report","title":"<code>ingest report</code>","text":"<p>Run Koza QC on specified Monarch ingests</p> <p>Usage:</p> <pre><code>$ ingest report [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"CLI/#ingest-solr","title":"<code>ingest solr</code>","text":"<p>Usage:</p> <pre><code>$ ingest solr [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"CLI/#ingest-sqlite","title":"<code>ingest sqlite</code>","text":"<p>Usage:</p> <pre><code>$ ingest sqlite [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"CLI/#ingest-transform","title":"<code>ingest transform</code>","text":"<p>Run Koza transformation on specified Monarch ingests</p> <p>Usage:</p> <pre><code>$ ingest transform [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>-o, --output-dir TEXT</code>: Directory to output data  [default: output]</li> <li><code>-i, --ingest TEXT</code>: Run a single ingest (see ingests.yaml for a list)</li> <li><code>--ingests TEXT</code>: Which ingests to download data for</li> <li><code>--phenio / --no-phenio</code>: Run the phenio transform  [default: no-phenio]</li> <li><code>-a, --all</code>: Ingest all sources</li> <li><code>-f, --force</code>: Force ingest, even if output exists (on by default for single ingests)</li> <li><code>--rdf / --no-rdf</code>: Output rdf files along with tsv  [default: no-rdf]</li> <li><code>-d, --debug / -q, --quiet</code>: Use --quiet to suppress log output, --debug for verbose, including Koza logs</li> <li><code>-l, --log</code>: Write DEBUG level logs to ./logs/ for each ingest</li> <li><code>-n, --row-limit INTEGER</code>: Number of rows to process</li> <li><code>--write-metadata / --no-write-metadata</code>: Write data/package versions to output_dir/metadata.yaml  [default: no-write-metadata]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"Create-an-Ingest/","title":"What is an Ingest?","text":"<p>Ingest Overview</p> <p>An ingest consists of 2 main steps:  </p> <ul> <li>Downloading the data  </li> <li>Transforming the data  </li> </ul> <p>With 2 post-processing steps:</p> <ul> <li>Merging the output into a KGX knowledge graph</li> <li>Releasing the result to the Monarch Initiative Google Cloud bucket</li> </ul> <p>Let's go through the process for running an existing monarch ingest!</p> <p>Step 1. Download</p> <ul> <li> <p>Download the dataset for your ingest, for example:     <pre><code>ingest download --tags ncbi_gene\n</code></pre></p> <p>or to download all source data: <pre><code>ingest download --all\n</code></pre></p> </li> </ul> <p>Step 2. Transform</p> <ul> <li> <p>Transform the data, for example:     <pre><code>ingest transform --tag ncbi_gene --row-limit 20 --log\n</code></pre></p> <p>or </p> <pre><code>ingest transform --all\n</code></pre> </li> </ul> <p>Step 3. Merge</p> <ul> <li>This step is typically performed after <code>ingest transform --all</code>, and merges all output node and edge files into a tar.gz containing one node and one edge file:     <pre><code>ingest merge\n</code></pre></li> </ul> <p>Step 4. Release</p> <ul> <li>Once you've transformed all the data and merged the output, you can create and upload a release:     <pre><code>ingest release\n</code></pre></li> </ul> <p>-- Now let's look at how to create and add a new ingest! First step: Propose a new Ingest</p>"},{"location":"Create-an-Ingest/1.%20Propose/","title":"Propose","text":"<ol> <li>Propose an Ingest: create a ticket on GitHub Ingest that includes the name of the source and justification for it's inclusion in Monarch. Assign the ticket to @putmantime &amp; @sagehrke (Monarch PM). Who: Anyone can submit a proposal.</li> <li>Estimate Workload: Utilize planning poker to identify the amount of work the proposed ingest will be. Who: Monarch Technical Team. The Monarch PM will initialize the planning poker vote.</li> <li>Put up for vote &amp; discussion: Use voting on github (thumb up for approve / thumb down for reject). Voting &amp; discussion are open for two weeks. Who: Anyone can vote on a proposal. The Monarch PM will initialize the vote.</li> <li>If voted positive: assign the ingest to a team member, start working on ingest, then create a PR. Skip to Step 6. Who: Monarch Technical Team</li> <li>If voted negative, note why it was downvoted and close the issue. Who: Monarch Technical Team</li> <li>Disseminate the proposed model and gather feedback: Send an email to the Monarch Leads Google Group and the slack ingest channel (kg-monarch) requesting input. All discussions are done in GitHub on the PR. Tag those that need to respond in a comment on the PR. The feedback stage is open for two weeks. Who: Monarch Technical Team member assigned to the PR in Step 4 will disseminate the proposal. Anyone can comment or suggest input.</li> <li>Deploy the new ingest Who: Monarch Technical Team</li> </ol> <p>Now let's look at how to create and add a new ingest! First step: Configure</p>"},{"location":"Create-an-Ingest/2.%20Configure/","title":"Configure","text":"<ol> <li> <p>Make a directory for your ingest, using the source of the data as the name: <pre><code>mkdir src/monarch_ingest/ingests/&lt;source&gt; \n</code></pre> For example: <pre><code>mkdir src/monarch_ingest/ingests/ncbi\n</code></pre></p> </li> <li> <p>Add data sources to <code>src/monarch_ingest/download.yaml</code>: <pre><code># &lt;source&gt;\n-\n  url: https://&lt;source&gt;.com/downloads/somedata.txt \n  local_name: data/&lt;source&gt;/somedata.txt\n  tag: &lt;source&gt;_&lt;ingest&gt;                             \n</code></pre> For example: <pre><code># mgi\n-\n  url: http://www.informatics.jax.org/downloads/reports/MRK_Reference.rpt\n  local_name: data/mgi/MRK_Reference.rpt\n  tag: mgi_publication_to_gene   \n</code></pre></p> <p>Note: You can now use <code>ingest download --tags &lt;tag&gt;</code> or <code>ingest download --all</code>, and your data will be downloaded to the appropriate subdir in <code>data/</code> </p> </li> <li> <p>Add your ingest to <code>src/monarch_ingest/ingests.yaml</code>: <pre><code>&lt;ingest_name&gt;:\n  config: 'ingests/&lt;source&gt;/&lt;ingest&gt;.yaml\n</code></pre> For example: <pre><code>ncbi_gene:\n  config: 'ingests/ncbi/gene.yaml'\n</code></pre></p> </li> <li> <p>Copy the template: <pre><code>cp ingest_template/* src/monarch_ingest/ingests/&lt;source&gt;\n</code></pre></p> </li> <li> <p>Edit <code>metadata.yaml</code>:  </p> <ul> <li>Update the description, rights link, url, etc and then add your source_file</li> </ul> </li> <li> <p>Edit the source file yaml</p> <ul> <li>Match the columns or required fields with what's available in the file to be ingested<ul> <li>If it's an ingest that exists in Dipper, check out what Dipper does.</li> <li>Check the Biolink Model documentation to look at what you can capture</li> <li>If what we need from an ingest can't be captured in the model yet, make a new Biolink issue</li> </ul> </li> <li>Set the header properties<ul> <li>If there is no header at all, set <code>header: False</code></li> <li>If there are comment lines before the header, count them and set <code>skip_lines: {n}</code></li> </ul> </li> </ul> </li> </ol> <p>--     Next step:  Adding documentation</p>"},{"location":"Create-an-Ingest/3.%20Document/","title":"Document","text":"<p>The documentation for an ingest should reflect both the decision-making process that led to the output, and the output itself. </p> <p>Begin by copying the <code>source.md</code> file to the <code>docs/Sources/</code> folder, renaming it to match the ingest name.</p> <p>Tip</p> <p>This is a great time to look over the columns in the ingest file. Consider what biolink classes are appropriate to represent them, and what fields are available to populate on each.</p> <p>Some helpful resources:</p> <ul> <li>Biolink Documentation</li> <li>List of Biolink Associations</li> <li>Use a Jupyter Notebook with Biolink Model Toolkit to do things like <code>get_element_by_mapping('RO:0002410')</code></li> <li>For ingests migrating from Dipper, check out the documentation and source code</li> </ul> <p>--  Next step: Begin implementation</p>"},{"location":"Create-an-Ingest/4.%20Implement/","title":"Implement","text":"<p>Most Koza scripts can run in flat mode, which means that the transform code itself doesn't need to handle the looping mechanism, and instead the transform code will have a row injected at the top and call the write command at the bottom. In between fields from the incoming row should be mapped to Biolink instances. </p>"},{"location":"Create-an-Ingest/4.%20Implement/#imports-and-setup","title":"Imports and setup","text":"<p>Start with the imports, and make sure to set the source_name, which will be used for communicating with the reader and writer.</p> <pre><code>from koza.cli_utils import koza_app\nfrom biolink.pydanticmodel_v2 import Gene\n\n# The source name is used for reading and writing\nsource_name = \"gene-information\"\n</code></pre>"},{"location":"Create-an-Ingest/4.%20Implement/#inject-the-row","title":"Inject the row","text":"<pre><code># inject a single row from the source\nrow = koza_app.get_row(source_name)\n</code></pre>"},{"location":"Create-an-Ingest/4.%20Implement/#extras","title":"Extras","text":"<p>Next up handle any additional set up for the ingest, such as including a map or bringing in the CURIE cleaning service</p> <pre><code>curie_cleaner = koza_app.curie_cleaner\neqe2zp = koza_app.get_map(\"eqe2zp\")\ntranslation_table = koza_app.translation_table\n</code></pre>"},{"location":"Create-an-Ingest/4.%20Implement/#creating-entities","title":"Creating entities","text":"<p>At this step, hopefully your documentation is so good that you're just letting your fingers take on the last step of converting what you've already planned into Python syntax. Ideally not much logic will be needed here, and if there's a lot, it might be worth considering whether an ingest (even on the same file) can be split across multiple transforms so that each is as easy to read as possible. Aim to add all properties when creating the instance, but in some cases adding optional lists might need to happen below. </p> <pre><code>from biolink.pydanticmodel_v2 import Gene\ngene = Gene(\n    id='somethingbase:'+row['ID'],\n    name=row['Name']\n)\n\n# populate any additional optional properties\nif row['xrefs']:\n    gene.xrefs = [curie_cleaner.clean(xref) for xref in row['xrefs']]\n</code></pre>"},{"location":"Create-an-Ingest/4.%20Implement/#writing","title":"Writing","text":"<p>At the end of the script, call the writer. The first argument must be the source_name (so that it will know where to write), entities should be passed in as additional arguments.</p> <pre><code>koza_app.write(gene, phenotypicFeature, association)\n</code></pre>"},{"location":"Create-an-Ingest/4.%20Implement/#running-your-ingest","title":"Running your ingest","text":"<p>To execute your ingest, you can now run: <pre><code>ingest transform --tag &lt;your-ingest-tag&gt;\n</code></pre></p> <p>-- Next step: Testing!</p>"},{"location":"Create-an-Ingest/5.%20Test/","title":"Testing","text":"<p>You may want to start with the test template within <code>ingest_template</code></p>"},{"location":"Create-an-Ingest/5.%20Test/#basic-fixtures","title":"Basic fixtures","text":"<p>First, set up your basic fixtures, taking care to set the correct source name and location for the transform code.</p> <pre><code>import pytest\nfrom koza.cli_utils import get_translation_table\n\n@pytest.fixture\ndef tt():\n    return get_translation_table(\"src/monarch_ingest/translation_table.yaml\", None)\n\n# This name must match the ingest name in the transform code\n@pytest.fixture\ndef source_name():\n    return \"something-to-somethingelse\"\n\n# This is the location of the transform code\n@pytest.fixture\ndef script():\n    return \"./src/monarch_ingest/ingests/somethingbase/something2somethingelse.py\"\n</code></pre>"},{"location":"Create-an-Ingest/5.%20Test/#a-map-if-necessary","title":"A map, if necessary","text":"<p>Some ingests will depend on one or more maps, that fixture can be set up here. Note that this fixture must return a map of maps, and that the inner maps will map from an ID to a dictionary representing column headers and values. </p> <p>In the example below, a map is created that maps from a big concatenated natural key (as the ID) for ZP to a single column (called <code>iri</code>) that contains the ZP ID. </p> <p>This map is then placed into the map cache under the name <code>eqe2zp</code> <pre><code>@pytest.fixture\ndef map_cache():\n    eqe2zp = {\n        \"0-0-ZFA:0000042-PATO:0000638-0-0-0\": {\"iri\": \"ZP:0004225\"},\n        \"BSPO:0000112-BFO:0000050-ZFA:0000042-PATO:0000638-0-0-0\": {\n            \"iri\": \"ZP:0011243\"\n        },\n        \"BSPO:0000000-BFO:0000050-ZFA:0000823-PATO:0000642-BSPO:0000007-BFO:0000050-ZFA:0000823\": {\n            \"iri\": \"ZP:0000157\"\n        },\n    }\n    return {\"eqe2zp\": eqe2zp}\n</code></pre></p>"},{"location":"Create-an-Ingest/5.%20Test/#fixtures-for-test-data","title":"Fixtures for test data","text":"<p>Create a fixture that returns a dictionary to represent a single row. As a matter of strategy, this row should probably represent a fairly basic row being ingested. </p> <p>One trick so that you don't have to manually convert from the imput format to a python dictionary format is to run your ingest with a debugger and set a breakpoint just after a row has been injected. If you want a more specific piece of data, check out conditional breakpoints. </p> <pre><code>@pytest.fixture\ndef basic_row():\n    return {\n        \"ID\": \"341492416\",\n        \"Gene Symbol\": \"pax2a\",\n        \"Gene ID\": \"ZDB-GENE-990415-8\",\n         #...\n        \"Fish Environment ID\": \"ZDB-GENOX-041102-1385\",\n        \"Publication ID\": \"ZDB-PUB-970210-19\",\n        \"Figure ID\": \"ZDB-FIG-120307-8\",\n    }\n</code></pre>"},{"location":"Create-an-Ingest/5.%20Test/#fixture-for-transforming-a-single-row","title":"Fixture for transforming a single row","text":"<p>This sets up a fixture you can call more than once to independently test different attributes</p> <pre><code>@pytest.fixture\ndef basic_g2p(mock_koza, source_name, basic_row, script, map_cache, tt):\n    return mock_koza(\n        source_name,\n        iter([basic_row]),\n        script,\n        map_cache=map_cache,\n        translation_table=tt,\n    )\n</code></pre>"},{"location":"Create-an-Ingest/5.%20Test/#test-the-basics-of-the-ingest","title":"Test the basics of the ingest","text":"<p>Confirm that entities are created matching the expectations on the row</p> <pre><code># A simple end-to-end test is to confirm that the IDs are set on\ndef test_gene(basic_g2p):\n    gene = basic_g2p[0]\n    assert gene\n    assert gene.id == \"ZFIN:ZDB-GENE-990415-8\"\n\n\ndef test_phenotypic_feature(basic_g2p):\n    phenotypic_feature = basic_g2p[1]\n    assert phenotypic_feature\n    assert phenotypic_feature.id == \"ZP:0004225\"\n\n\ndef test_association(basic_g2p):\n    association = basic_g2p[2]\n    assert association\n    assert association.subject == \"ZFIN:ZDB-GENE-990415-8\"\n    assert association.object == \"ZP:0004225\"\n    assert association.publications\n    assert association.publications[0] == \"ZFIN:ZDB-PUB-970210-19\"\n</code></pre>"},{"location":"Create-an-Ingest/5.%20Test/#test-against-an-alternate-row","title":"Test against an alternate row","text":"<p>For any branching within the transform code, it's a good idea to test against all of the paths through the code. It's possible to set conditional breakpoints to find real examples in the code that will hit each code path, but it may be more practical to modify the basic row as a new fixture</p> <p>The example below creates a row with additional columns filled in.</p> <pre><code>@pytest.fixture\ndef postcomposed(mock_koza, source_name, basic_row, script, map_cache, tt):\n\n    basic_row[\"Affected Structure or Process 1 subterm ID\"] = \"BSPO:0000112\"\n    basic_row[\"Post-composed Relationship ID\"] = \"BFO:0000050\"\n    basic_row[\"Affected Structure or Process 1 superterm ID\"] = \"ZFA:0000042\"\n\n    return mock_koza(\n        source_name,\n        iter([basic_row]),\n        script,\n        map_cache=map_cache,\n        translation_table=tt,\n    )\n</code></pre>"},{"location":"Create-an-Ingest/5.%20Test/#parameterized-tests","title":"Parameterized tests","text":"<p>Mixing parameterization and fixtures changes the approach a little. In this case it makes more sense to alter the row using a parameter and then create the entities within the same method.  </p> <p>The test below is intended to confirm that when the tag column has any of the specified values, the row will be ignored (confirmed because no entities are created).</p> <pre><code>@pytest.mark.parametrize(\"tag\", [\"normal\", \"exacerbated\", \"ameliorated\"])\ndef test_excluded_tags(mock_koza, source_name, basic_row, script, map_cache, tt, tag):\n    basic_row[\"Phenotype Tag\"] = tag\n    entities = mock_koza(\n        source_name,\n        iter([basic_row]),\n        script,\n        map_cache=map_cache,\n        translation_table=tt,\n    )\n    assert len(entities) == 0\n</code></pre>"},{"location":"KG-Build-Process/kg-build-process/","title":"Monarch KG Build Process","text":""},{"location":"KG-Build-Process/kg-build-process/#download","title":"Download","text":"<p>A weekly job indepent from the KG build process runs to download data sources and store then on a cloud bucket. This replaces DipperCache from the old pipeline. KGHub Downloader reads from downloads.yaml to download each file. Some post-processing is done in a shell script before the files are uploaded to the cloud bucket.</p> <p>At the start of the main ingest build, data files are copied from the cloud bucket.</p>"},{"location":"KG-Build-Process/kg-build-process/#transform","title":"Transform","text":"<p>A call to the ingest command line tool runs each source ingest defined in ingest.yaml, producing both KGX tsv and RDF nt output. </p>"},{"location":"KG-Build-Process/kg-build-process/#source-ingests","title":"Source Ingests","text":"<p>Ingests are documented individually in the Sources section of this documentation. Ingests are either node or edge specific, and use IDs as defined in the source data files without additional re-mapping of identifiers. The primary role they have is to represent sources in biolink model and KGX format, and secondarily they may also subset from the source files. The output of individual ingests can be found in the transform_output directory in each release.</p>"},{"location":"KG-Build-Process/kg-build-process/#phenio-kg","title":"Phenio-KG","text":"<p>Ontologies in Monarch are built first as Phenio, then converted into the biolink model and represented as KGX in kg-phenio. </p> <p>The <code>ingest</code> CLI has transform_phenio method then performs some further filtering on the kg-phenio node and edge files. Limiting to nodes and edges that match a subset of curie namespaces, and limiting node property columns to a relevant subset.</p>"},{"location":"KG-Build-Process/kg-build-process/#merge","title":"Merge","text":"<p>With all transforms complete, the individual kgx node and edge files in <code>output/transform_output</code> can be combined into a merged graph. This is done by the <code>merge</code> command in the <code>ingest</code> CLI. </p> <p>At this point, the individual node and edge KGX files from the transforms may not have matching IDs, and in fact, we may have edges that point to nodes that are not present in our canonical node sources (e.g. a STRING edge that points to an ENSEMBL gene that can't be mapped to HGNC). </p> <p>The merge process is broken down into concatenation, mapping, and finally a QC filter step. We developed a tool called cat merge</p>"},{"location":"KG-Build-Process/kg-build-process/#concatenate","title":"Concatenate","text":"<p>The first step just loads all node kgx files into one dataframe, and all edge kgx files into another.</p>"},{"location":"KG-Build-Process/kg-build-process/#map","title":"Map","text":"<p>The mapping step replaces subject and object IDs in edge files using SSSOM mapping files, with the IDs from the intial ingests stored in <code>original_subject</code> and <code>original_object</code> fields. </p> <p>Mappings for genes are generated in our monarch-gene-mapping process, and are available at data.monarchinitiative.org. </p> <p>Diseases are mapped using the MONDO SSSOM. </p> <p>This step is requires that the subject of the SSSOM file be our canonical ID, and the object be the non-canonical ID. There is room for improvement here. </p>"},{"location":"KG-Build-Process/kg-build-process/#qc-filter","title":"QC Filter","text":"<p>After edges have been mapped, it's important to cull the graph that point to nodes that don't exist in the graph. The QC filtering step performs joins against the node table/dataframe to split out these edges into their own kgx file (monarch-kg-dangling-edges.tsv that can be used for QC purposes.</p> <p>A group of edges that wind up in this file could be due to a number of reasons: * We're missing an ontology or other node source that is required for an ingest/source: this is something we want to fix \ud83d\udc4e * We're missing mapping necessary to translate between an edge ingest and our canonical node sources: this is something we want to fix \ud83d\udc4e * The edge ingest includes edges which can't be mapped to our canonical node sources: this is a feature! \ud83d\udc4d</p> <p>We have a visualization of this split between connected and dangling edges for each ingest on our QC Dashboard that we can use to problem-solve our mappings and node sources.</p>"},{"location":"KG-Build-Process/kg-build-process/#neo4j","title":"Neo4j","text":"<p>A neo4j dump is created using the merged tar.gz file using KGX's neo4j loader and a docker container. This process is defined directly in the Jenkinsfile.</p>"},{"location":"KG-Build-Process/kg-build-process/#denormalize","title":"Denormalize","text":"<p>For Solr (and secondarily SQLite) we produce a denormalized edge file, which includes additional details for the subjects and objects of each edge, including the category, namespace/prefix, and ontology ancestor closures following the GOLR pattern (ID and label closure lists). The closure file is generated by relation-graph and are included in the kg-phenio download. The after_download script makes a filtered version that only includes <code>rdfs:subClassOf</code>, <code>BFO:0000050</code>, and <code>UPHENO:0000001</code>.</p>"},{"location":"KG-Build-Process/kg-build-process/#sqlite","title":"SQLite","text":"<p>A SQLite database file is produced by loading node and edge files into a SQLite database using a simple shell script, along with the primary node and edge tables, edge tables for danging and denormalized edges are included as well. </p>"},{"location":"KG-Build-Process/kg-build-process/#solr","title":"Solr","text":"<p>Our solr index is loaded directly from the node kgx tsv file and the denormalized edge tsv file using LinkML-Solr. The LinkML schema for the Solr index is lives in the monarch-py data access library (see documentation for Entity and Association classes). </p> <p>LinkML-Solr starts Solr in docker via the <code>lsolr</code> command, defines the Solr schema based on the LinkML Schema and then bulk loads the data. Currently, a small amount of additional Solr configuration (defining new field types, and copy-fields declarations to fill them) is done via curl commands in shell scripts. </p> <p>Our solr load process is defined in scripts/load_solr.sh</p>"},{"location":"Principles/modeling-principles/","title":"Modeling Principles","text":""},{"location":"Principles/modeling-principles/#conforms-to-schema","title":"Conforms to Schema","text":"<p>The Monarch Biolink Specification is an implementation of the Biolink Model. The KG must be conformant with The Monarch Biolink Specification.</p>"},{"location":"Principles/modeling-principles/#node-normalization","title":"Node Normalization","text":"<p>The final KG must have Nodes normalized to the canonical prefix for any given node type. The canonical prefix should be determined by The Monarch Biolink Model Specification.</p>"},{"location":"Principles/modeling-principles/#authoratative-source","title":"Authoratative Source","text":"<p>Providers of Associations are not the authoratative sources for the Nodes in general. Nodes should be ingested from their own authoratative source, seperate from edge ingests.</p>"},{"location":"Principles/modeling-principles/#genes-and-proteins","title":"Genes and Proteins","text":"<p>Genes and reference Proteins shall be treated as equivalent. When collapsing nodes give the Gene Id the priority, original_subject = UniProt Id. If in future there is a need to represent Isoforms, then UniProt Isoform Ids should be used.</p>"},{"location":"Principles/modeling-principles/#variants","title":"Variants","text":"<p>Variant to Disease/Phenotype Associations may be rolled up to the Gene level. If they are rolled up, then a subject_modifier = Variant Id.</p>"},{"location":"Principles/modeling-principles/#gene-to-disease-associations","title":"Gene to Disease Associations","text":"<p>Gene to Disease Associations should come from high quality sources that have been vetted by domain experts within Monarch. Gene to Disease Associations must not confuse single Gene causal Mendelian Associations with otherwise associated Genes. (e.g. contributing or associated Genes)</p>"},{"location":"Sources/","title":"Data Sources","text":"<p>This section contains detailed information on all datasets and ontologies ingested to create the Monarch knowledge graph.  </p> <p>To learn more about a specific dataset/ontology, click on the source name in the list to the left.  </p>"},{"location":"Sources/alliance/","title":"Alliance","text":"<p>The Alliance of Genome Resources contains a subset of model organism data from member databases that is harmonized to the same model. Over time, as the alliance adds additional data types, individual MOD ingests can be replaced by collective Alliance ingest. The Alliance has bulk data downloads, ingest data formats, and an API. The preference should be bulk downloads first, followed by ingest formats, finally by API calls. In some cases it may continue to be more practical to load from individual MODs when data is not yet fully harmonized in the Alliance.</p> <ul> <li>Alliance Bulk Downloads</li> <li>Alliance schemas</li> </ul>"},{"location":"Sources/alliance/#gene-information","title":"Gene Information","text":"<p>Genes for all Alliance species (Human, Rat, Mouse, Fish, Fly, Worm, Yeast, Frog) are loaded using the BGI formatted ingest files, as there are no Gene export files.</p> <p>Biolink captured</p> <ul> <li>biolink:Gene<ul> <li>id</li> <li>symbol</li> <li>name</li> <li>in_taxon</li> <li>source</li> <li>synonyms</li> <li>xref</li> <li>type ([\"SO:0001217\"])</li> </ul> </li> </ul>"},{"location":"Sources/alliance/#gene-to-phenotype","title":"Gene to Phenotype","text":"<p>Phenotype for the subset of Alliance species which use phenotype ontologies (Human, Rat, Mouse, Worm) are loaded using the phenotype ingest format, since there is not yet a phenotype export file from the Alliance. This file contains both Gene and Allele phenotypes, so a single column TSV is produced from BGI files listing Gene IDs to check the category and only genes are included. Environmental conditions are present for some species and are captured using the qualifier.</p> <p>Biolink captured</p> <ul> <li>biolink:GeneToPhenotypicFeatureAssociation<ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (has_phenotype)</li> <li>object (phenotypicFeature.id)</li> <li>publications</li> <li>qualifiers (condition terms)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\", \"infores:alliancegenome\"])</li> <li>primary_knowledge_source (<code>infores</code> mapped from row['Source'])</li> </ul> </li> </ul>"},{"location":"Sources/alliance/#gene-expression","title":"Gene Expression","text":"<p>This is the full data model of the Alliance file ingested; however, not all fields are currently used in the current ingest (in most cases, these fields are not yet set in the input data sets; see the gene_to_expression.yaml file)</p> <ul> <li>Species</li> <li>SpeciesID</li> <li>GeneID</li> <li>GeneSymbol</li> <li>Location</li> <li>StageTerm</li> <li>AssayID</li> <li>AssayTermName</li> <li>CellularComponentID</li> <li>CellularComponentTerm</li> <li>CellularComponentQualifierIDs</li> <li>CellularComponentQualifierTermNames</li> <li>SubStructureID</li> <li>SubStructureName</li> <li>SubStructureQualifierIDs</li> <li>SubStructureQualifierTermNames</li> <li>AnatomyTermID</li> <li>AnatomyTermName</li> <li>AnatomyTermQualifierIDs</li> <li>AnatomyTermQualifierTermNames</li> <li>SourceURL</li> <li>Source</li> <li>Reference</li> </ul> <p>Discussion Group: https://www.alliancegenome.org/working-groups#expression </p> <p>Download: https://www.alliancegenome.org/downloads#expression</p> <p>Biolink captured</p> <ul> <li> <p>biolink:Gene</p> <ul> <li>id (row['GeneID'])</li> <li>name (row['GeneSymbol'])</li> <li>in taxon (row['SpeciesID'])</li> <li>source (<code>infores</code> mapped from row['Source'])</li> </ul> </li> <li> <p>biolink:AnatomicalEntity</p> <ul> <li>id (row['AnatomyTermID'])</li> <li>name (row['AnatomyTermName'])</li> <li>source (<code>infores</code> mapped from row['Source'])</li> </ul> </li> <li> <p>biolink:CellularComponent  # is_a: anatomical entity...</p> <ul> <li>id (row['CellularComponentID'])</li> <li>name (row['CellularComponentTerm'])</li> <li>source (<code>infores</code> mapped from row['Source'])</li> </ul> </li> <li> <p>biolink:LifeStage</p> <ul> <li>id (CURIE heuristically inferred from row['SpeciesID'] and row['StageTerm'])</li> <li>name (row['StageTerm'])</li> <li>in taxon (row['SpeciesID'])</li> <li>source (<code>infores</code> mapped from row['Source'])</li> </ul> </li> <li> <p>biolink:GeneToExpressionSiteAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (Gene.id)</li> <li>predicates (biolink:expressed_in)</li> <li>object (AnatomicalEntity.id or CellularComponent.id)</li> <li>stage qualifier (LifeStage.id)  # if specified; None otherwise</li> <li>has evidence (row['AssayID'])  # e.g. taken from MMO - \"measurement method ontology\"</li> <li>publications (row['Reference'])</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\", \"infores:alliancegenome\"])</li> <li>primary_knowledge_source (<code>infores</code> mapped from row['Source'])</li> </ul> </li> </ul>"},{"location":"Sources/alliance/#literature","title":"Literature","text":"<p>The Alliance has a well defined literature ingest format that aligns publications from MOD members. </p> <p>Mapping of Alliance publication category to biolink category</p> Alliance category Biolink publication type Research Article IAO:0000013 Review Article IAO:0000013 Thesis IAO:0000311 Book IAO:0000311 Other IAO:0000311 Preprint IAO:0000013 Conference Publication IAO:0000311 Personal Communication IAO:0000311 Direct Data Submission IAO:0000311 Internal Process Reference IAO:0000311 Unknown IAO:0000311 Retraction IAO:0000311 <p>This ingest doesn't make an effort to sort these publication categories into more specific classes than biolink:Publication, but does set the type.</p> <p>Biolink captured</p> <ul> <li>biolink:Publication<ul> <li>id (primaryId) </li> <li>name (title)</li> <li>summary (abstract)</li> <li>authors (authors.name flattened as a comma separated string)</li> <li>xref (crossReferences.id)</li> <li>mesh terms (meshTerms.meshHeadingTerm , meshTerms.meshQualifierTerm)</li> <li>type (IAO:0000311 for publication, IAO:0000013 for article)</li> <li>creation date (datePublished)</li> <li>keywords (keywords)</li> </ul> </li> </ul>"},{"location":"Sources/alliance/#citation","title":"Citation","text":"<p>Harmonizing model organism data in the Alliance of Genome Resources. 2022. Alliance of Genome Resources Consortium. Genetics, Volume 220, Issue 4, April 2022. Published Online: 25 February 2022. doi: doi.org/10.1093/genetics/iyac022. PMID: 35380658;  PMCID: PMC8982023.</p>"},{"location":"Sources/bgee/","title":"BGee","text":"<p>Bgee is a database for retrieval and comparison of gene expression patterns across multiple animal species, produced from multiple data types (bulk RNA-Seq, single-cell RNA-Seq, Affymetrix, in situ hybridization, and EST data) and from multiple data sets (including GTEx data).</p>"},{"location":"Sources/bgee/#gene-expression","title":"Gene Expression","text":"<p>This is the full data model of the Bgee simple gene expression file; however, not all fields are currently used in the current ingest. Files are named by Species ID.</p> <ul> <li>\"Gene name\"</li> <li>Anatomical entity ID</li> <li>\"Anatomical entity name\"</li> <li>Expression</li> <li>Call quality</li> <li>FDR</li> <li>Expression score</li> <li>Expression rank</li> </ul> <p>Biolink Captured</p> <ul> <li>biolink:GeneToExpressionSiteAssociation<ul> <li>id (random uuid, generated)</li> <li>subject (<code>Gene ID</code>)</li> <li>predicates (biolink:expressed_in, constant)</li> <li>object (<code>Anatomical entity ID</code>)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\", \"infores:bgee\"])</li> </ul> </li> </ul> <p>Decisions and Discussion</p> <p>We elected to use the simple gene expression file for ease of use and because the advanced doesn't contain much more data we are likely to use. We could potentially import <code>has evidence</code> from the advanced file comparing <code>Affimetrix expression</code> and <code>RNA-Seq expression</code> but this doesn't seem valuable at this time. Stage and Strain information is also available in all_conditions file. We have elected to not import the stage information due to multiple duplicate edges based on strain.</p>"},{"location":"Sources/bgee/#citation","title":"Citation","text":"<p>\"Bastian FB, Roux J, Niknejad A, Comte A, Fonseca Costa SS, Mendes de Farias T, Moretti S, Parmentier G, Rech de Laval V, Rosikiewicz M, Wollbrett J, Echchiki A, Escoriza A, Gharib W, Gonzales-Porta M, Jarosz Y, Laurenczy B, Moret P, Person E, Roelli P, Sanjeev K, Seppey M, Robinson-Rechavi M.  The Bgee suite: integrated curated expression atlas and comparative transcriptomics in animals in Nucleic Acids Research, Volume 49, Issue D1, 8 January 2021, Pages D831-D847\"</p>"},{"location":"Sources/ctd/","title":"Comparative Toxicogenomics Database (CTD)","text":"<p>CTD is a robust, publicly available database that aims to advance understanding about how environmental exposures affect human health. It provides manually curated information about chemical\u2013gene/protein interactions, chemical\u2013disease and gene\u2013disease relationships. These data are integrated with functional and pathway data to aid in development of hypotheses about the mechanisms underlying environmentally influenced diseases.</p> <ul> <li>CTD Bulk Downloads </li> </ul> <p>Chemical to Disease</p> <p>This ingest takes only the chemical to disease rows where a direct evidence label is applied, and creates ChemicalEntity and Disease nodes connected by a ChemicalToDiseaseOrPhenotypicFeatureAssociation. The the chemical ID row is expected to need a 'MESH:' prefix added, the disease id is used as-is. </p> <p>Rows are included only if the direct evidence field is 'therapeutic' and the <code>biolink:affects</code> predicate is used to avoid making too strong a claim.</p> <p>Biolink Captured</p> <ul> <li>ChemicalToDiseaseOrPhenotypicFeatureAssociation</li> <li>id (random uuid)</li> <li>subject (chemical id)</li> <li>predicate (<code>biolink:affects</code>)</li> <li>object (disease id)</li> <li>publication (pubmed ids provided by file)</li> <li>aggregating_knowledge_source (<code>[\"infores:monarchinitiative\"]</code>)</li> <li>primary_knowledge_source (<code>infores:ctd</code>)</li> </ul>"},{"location":"Sources/ctd/#citation","title":"Citation","text":"<p>Davis AP, Wiegers TC, Johnson RJ, Sciaky D, Wiegers J, Mattingly CJ Comparative Toxicogenomics Database (CTD): update 2023. Nucleic Acids Res. 2022 Sep 28.</p>"},{"location":"Sources/dictybase/","title":"Dictybase","text":"<p>Dictybase is a comprehensive database for the ameboid protozoan Dictyostelium discoideum, which is a powerful model system for genetic and functional analysis of gene function.</p> <ul> <li>Dictybase Bulk Downloads</li> </ul>"},{"location":"Sources/dictybase/#gene-information","title":"Gene Information","text":"<p>Dictybase genes in the Gene to Phenotype ingest (below) are either directly identified from their gene identifier, mapped directly to NCBI Dictyostelium discoideum gene identifier mappings or mapped indirectly from the Dictybase identifier, names and synonyms mappings, with synonyms being populated as available (Note: full gene product information is not captured at this time).</p>"},{"location":"Sources/dictybase/#gene-to-phenotype","title":"Gene to Phenotype","text":"<p>Data is available in a well-documented easy-to-parse GAF-like format with associations to an UPHENO-compliant ontology. Phenotypes are linked to Strains, and the Strains are linked to Genes.</p> <p>Biolink Captured</p> <ul> <li> <p>biolink:Gene</p> <ul> <li>'id' (NCBI or Dictybase)</li> <li>'category'</li> <li>'name'</li> <li>'symbol'</li> <li>'in_taxon'</li> <li>'source'</li> </ul> </li> <li> <p>biolink:PhenotypicFeature</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:GeneToPhenotypicFeatureAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (has_phenotype)</li> <li>object (phenotypicFeature.id)</li> <li>category (GeneToPhenotypicFeatureAssociation)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:dictybase)</li> </ul> </li> </ul>"},{"location":"Sources/dictybase/#citation","title":"Citation","text":"<p>Fey, P., Dodson, R., Basu, S., Chisholm, R. L. (2013). 'One Stop Shop for Everything Dictyostelium: dictyBase and the Dicty Stock Center'. Dictyostelium discoideum Protocols. Methods Mol. Biol. 983:59-92, edited by Ludwig Eichinger and Francisco Rivero.</p>"},{"location":"Sources/flybase/","title":"Flybase","text":"<p>FlyBase is the model organism database providing integrated genetic, genomic, phenomic, and biological data for Drosophila melanogaster.</p> <ul> <li>FlyBase bulk downloads</li> </ul>"},{"location":"Sources/flybase/#gene-literature","title":"Gene Literature","text":"<p>This ingest uses FlyBase's publication-to-gene download file, which contains all entities and only assocations between publications and genes that are denoted in some way in the publication. We have selected to use a consistent high level term for 'publication' (IAO:0000311) as it is heterogeneous mix of publication types being referenced. We have also opted to use the FlyBase_publication_id for the publication node if PubMed_id is not available, on the assumption that kgx will clique merge them later.</p> <p>Biolink captured</p> <ul> <li> <p>biolink:Gene</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:Publication</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:InformationContentEntityToNamedThingAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (mentions)</li> <li>object (publication.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:flybase)</li> </ul> </li> </ul>"},{"location":"Sources/flybase/#citation","title":"Citation","text":"<p>Gramates LS, Agapite J, Attrill H, Calvi BR, Crosby M, dos Santos G Goodman JL, Goutte-Gattat D, Jenkins V, Kaufman T, Larkin A, Matthews B, Millburn G, Strelets VB, and the FlyBase Consortium (2022) FlyBase: a guided tour of highlighted features. Genetics, Volume 220, Issue 4, April 2022, iyac035</p>"},{"location":"Sources/go/","title":"Gene Ontology (GO) Annotation Database","text":"<p>The Gene Ontology Annotation Database compiles high-quality Gene Ontology (GO) annotations to proteins in the UniProt Knowledgebase (UniProtKB), RNA molecules from RNACentral and protein complexes from the Complex Portal.</p> <p>Manual annotation is the direct assignment of GO terms to proteins, ncRNA and protein complexes by curators from evidence extracted during the review of published scientific literature, with an appropriate evidence code assigned to give an assessment of the strength of the evidence.  GOA files contain a mixture of manual annotation supplied by members of the Gene Ontology Consortium and computationally assigned GO terms describing gene products. Annotation type is clearly indicated by associated evidence codes and there are links to the source data.</p>"},{"location":"Sources/go/#go-annotations","title":"GO Annotations","text":"<p>There is a ReadMe.txt file that explains the different annotation files available.  The ingested Gene Annotation File (GAF) is a 17 column tab-delimited file. The file format conforms to the specifications demanded by the GO Consortium and therefore GO IDs and not GO term names are shown.</p> <p>Biolink captured</p>"},{"location":"Sources/go/#subject-concept-node-gene","title":"Subject Concept Node (Gene)","text":"<ul> <li>biolink:Gene</li> <li>id (NCBIGene Entrez ID)</li> </ul>"},{"location":"Sources/go/#object-concept-node-gene-ontology-terms","title":"Object Concept Node (Gene Ontology Terms)","text":"<ul> <li>biolink:MolecularActivity</li> <li> <p>id (GO ID)</p> </li> <li> <p>biolink:BiologicalProcess</p> </li> <li> <p>id (GO ID)</p> </li> <li> <p>biolink:CellularComponent</p> </li> <li>id (GO ID)</li> </ul>"},{"location":"Sources/go/#additional-gene-ontology-term-concept-nodes-for-possible-use","title":"Additional Gene Ontology Term Concept Nodes for possible use?","text":"<ul> <li>biolink:Pathway</li> <li> <p>id (GO ID)</p> </li> <li> <p>biolink:PhysiologicalProcess</p> </li> <li>id (GO ID)</li> </ul> <p>Associations</p> <ul> <li>biolink:FunctionalAssociation<ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (related_to)</li> <li>object (go_term.id)</li> <li>negated</li> <li>has_evidence</li> <li>publications</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source</li> </ul> </li> </ul> <p>OR</p> <ul> <li> <p>biolink:MacromolecularMachineToMolecularActivityAssociation:</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (related_to)</li> <li>object (go_term.id)</li> <li>negated</li> <li>has_evidence</li> <li>publications</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source</li> </ul> </li> <li> <p>biolink:MacromolecularMachineToBiologicalProcessAssociation:</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (participates_in)</li> <li>object (go_term.id)</li> <li>negated</li> <li>has_evidence</li> <li>publications</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source</li> </ul> </li> <li> <p>biolink:MacromolecularMachineToCellularComponentAssociation:</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (located_in)</li> <li>object (go_term.id)</li> <li>negated</li> <li>has_evidence</li> <li>publications</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source</li> </ul> </li> </ul> <p>Possible Additional Gene to Gene Ontology Term Association?</p> <ul> <li>biolink:GeneToGoTermAssociation:<ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (related_to)</li> <li>object (go_term.id)</li> <li>negated</li> <li>has_evidence</li> <li>publications</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source</li> </ul> </li> </ul>"},{"location":"Sources/go/#citation","title":"Citation","text":"<p>Ashburner et al. Gene ontology: tool for the unification of biology. Nat Genet. 2000 May;25(1):25-9.  The Gene Ontology Consortium. The Gene Ontology knowledgebase in 2023. Genetics. 2023 May 4;224(1):iyad031</p>"},{"location":"Sources/hgnc/","title":"HGNC (HUGO Gene Nomenclature Committee)","text":"<p>The HGNC is responsible for approving unique symbols and names for human loci, including protein coding genes, ncRNA genes and pseudogenes, to allow unambiguous scientific communication.</p> <ul> <li>HGNC bulk downloads</li> </ul>"},{"location":"Sources/hgnc/#gene-information","title":"Gene Information","text":"<p>This ingest uses HGNC's \"complete set\" download file, which only contains associations between publications and genes that are denoted in some way in the publication. We have selected to use a consistent high level term for 'publication' (IAO:0000311) as it is heterogeneous mix of publication types being referenced. </p> <p>SO terms to populate the type are taken from the Alliance genome HGNC BGI files, provided by RGD.</p> <p>Biolink Captured</p> <ul> <li>biolink:Gene<ul> <li>id (HGNC identifier)</li> <li>symbol</li> <li>name</li> <li>synonym</li> <li>alias symbol</li> <li>alias name</li> <li>prev symbol</li> <li>prev name</li> <li>xref</li> <li>ensembl gene id</li> <li>omim id</li> <li>in_taxon ([\"NCBITaxon:9606\"])</li> <li>provided_by  ([\"infores:hgnc\"])</li> <li>type ([\"SO:0001217\"])</li> </ul> </li> </ul>"},{"location":"Sources/hgnc/#citation","title":"Citation","text":"<p>HGNC Database, HUGO Gene Nomenclature Committee (HGNC), European Molecular Biology Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Genome Campus, Hinxton, Cambridge CB10 1SD, United Kingdom www.genenames.org. </p>"},{"location":"Sources/hpoa/","title":"Human Phenotype Ontology Annotations (HPOA)","text":"<p>The Human Phenotype Ontology group curates and assembles over 115,000 annotations to hereditary diseases using the HPO ontology. Here we create Biolink associations between diseases and phenotypic features, together with their evidence, and age of onset and frequency (if known).</p> <p>There are four HPOA ingests - 'disease-to-phenotype', 'disease-to-mode-of-inheritance', 'gene-to-disease' and 'disease-to-mode-of-inheritance' - that parse out records from the HPO Annotation File.</p> <p>The 'disease-to-phenotype', 'disease-to-mode-of-inheritance' and 'gene-to-disease' parsers currently only process the \"abnormal\" annotations. Association to \"remarkable normality\" may be added in the near future.</p> <p>The 'disease-to-mode-of-inheritance' ingest script parses 'inheritance' record information out from the annotation file.</p>"},{"location":"Sources/hpoa/#gene-to-disease","title":"Gene to Disease","text":"<p>This ingest replaces the direct OMIM ingest so that we share g2d associations 1:1 with HPO. The mapping between association_type and biolink predicates shown below is the one way in which this ingest is opinionated, but attempts to be a direct translation into the biolink model.</p> <p>genes_to_disease.txt with the following fields:</p> <ul> <li>'ncbi_gene_id'</li> <li>'gene_symbol'</li> <li>'association_type'</li> <li>'disease_id'</li> <li>'source'</li> </ul> <p>Biolink Captured</p> <ul> <li>biolink:CorrelatedGeneToDiseaseAssociation or biolink:CausalGeneToDiseaseAssociation (depending on predicate)<ul> <li>id (random uuid)</li> <li>subject (ncbi_gene_id)</li> <li>predicate (association_type)</li> <li>MENDELIAN: <code>biolink:causes</code></li> <li>POLYGENIC: <code>biolink:contributes_to</code></li> <li>UNKNOWN: <code>biolink:gene_associated_with_condition</code></li> <li>object (disease_id)</li> <li>primary_knowledge_source (source)</li> <li>medgen: <code>infores:omim</code></li> <li>orphanet: <code>infores:orphanet</code></li> <li>aggregator_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>also for medgen: <code>infores:medgen</code></li> </ul> </li> </ul>"},{"location":"Sources/hpoa/#disease-to-phenotype","title":"Disease to Phenotype","text":"<p>phenotype.hpoa: A description of this file is found here, has the following fields:</p> <ul> <li>'database_id'</li> <li>'disease_name'</li> <li>'qualifier'</li> <li>'hpo_id'</li> <li>'reference'</li> <li>'evidence'</li> <li>'onset'</li> <li>'frequency'</li> <li>'sex'</li> <li>'modifier'</li> <li>'aspect'</li> <li>'biocuration'</li> </ul> <p>Note that we're calling this the disease to phenotype file because - using the YAML file filter configuration for the ingest - we are only parsing rows with Aspect == 'P' (phenotypic anomalies), but ignoring all other Aspects.</p> <p>Frequencies</p> <p>The 'Frequency' field of the aforementioned phenotypes.hpoa file has the following definition, excerpted from its Annotation Format page:</p> <pre><code>8. Frequency: There are three allowed options for this field. (A) A term-id from the HPO-sub-ontology below the term \u201cFrequency\u201d (HP:0040279). (since December 2016 ; before was a mixture of values). The terms for frequency are in alignment with Orphanet. * (B) A count of patients affected within a cohort. For instance, 7/13 would indicate that 7 of the 13 patients with the specified disease were found to have the phenotypic abnormality referred to by the HPO term in question in the study referred to by the DB_Reference; (C) A percentage value such as 17%.\n</code></pre> <p>Previously this ingest attempted to map the quantitative frequency values to HPO frequency terms. The only frequency mapping that occurs is between numerical values now, if a fraction is given it will be split into has_count and has_total, and has_quotient will be calculated by division of has_count/has_total, and has_percentage will be calculated by multiplying has_quotient by 100.</p> <p>Reference</p> <p>The phenotype.hpoa format includes a <code>DB_reference</code> field described as:</p> <pre><code> 5. DB_Reference: This required field indicates the source of the information used for the annotation. This may be the clinical experience of the annotator or may be taken from an article as indicated by a PubMed id. Each collaborating center of the Human Phenotype Ontology consortium is assigned a HPO:Ref id. In addition, if appropriate, a PubMed id for an article describing the clinical abnormality may be used.\n</code></pre> <p>This ingest preserves values of DB_reference which are not duplicates of the database_id captured as the subject, and will ultimately be found in <code>original_subject</code> in the graph when the subject is mapped via SSSOM to a Mondo identifier.</p> <p>Biolink captured</p> <ul> <li>biolink:DiseaseToPhenotypicFeatureAssociation<ul> <li>id (random uuid)</li> <li>subject (disease.id)</li> <li>predicate (has_phenotype)</li> <li>negated (True if 'qualifier' == \"NOT\")</li> <li>object (phenotypicFeature.id)</li> <li>publications (List[publication.id])</li> <li>has_evidence (List[Note [1]]),</li> <li>sex_qualifier (Note [2]) </li> <li>onset_qualifier (Onset.id)</li> <li>frequency_qualifier (Note [3])</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (\"infores:hpo-annotations\")</li> </ul> </li> </ul> <p>Notes: 1. CURIE of [Evidence and Conclusion Ontology(https://bioportal.bioontology.org/ontologies/ECO)] term 2. female -&gt; PATO:0000383, male -&gt; PATO:0000384 or None 3. See the Frequencies section above.</p>"},{"location":"Sources/hpoa/#disease-to-modes-of-inheritance","title":"Disease to Modes of Inheritance","text":"<p>Same as above, we again parse the phenotype.hpoa file.</p> <p>However, we're calling this the 'disease to modes of inheritance' file because - using the YAML file filter configuration for the ingest - we are only parsing rows with Aspect == 'I' (inheritance), but ignoring all other Aspects.</p> <p>Biolink captured</p> <ul> <li>biolink:DiseaseOrPhenotypicFeatureToGeneticInheritanceAssociation<ul> <li>id (random uuid)</li> <li>subject (disease.id)</li> <li>predicate (has_mode_of_inheritance)</li> <li>object (geneticInheritance.id)</li> <li>publications (List[publication.id])</li> <li>has_evidence (List[Note [1]]),</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (\"infores:hpo-annotations\")</li> </ul> </li> </ul>"},{"location":"Sources/hpoa/#gene-to-phenotype","title":"Gene to Phenotype","text":"<p>The gene-to-phenotype ingest processes the tab-delimited HPOA gene_to_phenotype.txt file, which has the following fields:</p> <ul> <li>'ncbi_gene_id'</li> <li>'gene_symbol'</li> <li>'hpo_id'</li> <li>'hpo_name'</li> </ul> <p>Biolink captured</p> <ul> <li>biolink:GeneToPhenotypicFeatureAssociation<ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (has_phenotype)</li> <li>object (phenotypicFeature.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:hpo-annotations)</li> </ul> </li> </ul>"},{"location":"Sources/hpoa/#citation","title":"Citation","text":"<p>Sebastian K\u00f6hler, Michael Gargano, Nicolas Matentzoglu, Leigh C Carmody, David Lewis-Smith, Nicole A Vasilevsky, Daniel Danis, Ganna Balagura, Gareth Baynam, Amy M Brower, Tiffany J Callahan, Christopher G Chute, Johanna L Est, Peter D Galer, Shiva Ganesan, Matthias Griese, Matthias Haimel, Julia Pazmandi, Marc Hanauer, Nomi L Harris, Michael J Hartnett, Maximilian Hastreiter, Fabian Hauck, Yongqun He, Tim Jeske, Hugh Kearney, Gerhard Kindle, Christoph Klein, Katrin Knoflach, Roland Krause, David Lagorce, Julie A McMurry, Jillian A Miller, Monica C Munoz-Torres, Rebecca L Peters, Christina K Rapp, Ana M Rath, Shahmir A Rind, Avi Z Rosenberg, Michael M Segal, Markus G Seidel, Damian Smedley, Tomer Talmy, Yarlalu Thomas, Samuel A Wiafe, Julie Xian, Zafer Y\u00fcksel, Ingo Helbig, Christopher J Mungall, Melissa A Haendel, Peter N Robinson, The Human Phenotype Ontology in 2021, Nucleic Acids Research, Volume 49, Issue D1, 8 January 2021, Pages D1207\u2013D1217, https://doi.org/10.1093/nar/gkaa1043</p>"},{"location":"Sources/mgi/","title":"Mouse Genome Informatics (MGI)","text":"<p>Mouse Genome Informatics (MGI) is the international database resource for the laboratory mouse, providing integrated genetic, genomic, and biological data to facilitate the study of human health and disease.</p> <ul> <li>MGI bulk downloads</li> </ul>"},{"location":"Sources/mgi/#gene-literature","title":"Gene Literature","text":"<p>This ingest uses MGI's Reference download file, which contains genes and a tab-delimited list of PubMed IDs in which they are mentioned. </p> <p>Biolink captured</p> <ul> <li> <p>biolink:Gene</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:Publication</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:InformationContentEntityToNamedThingAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (mentions)</li> <li>object (publication.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:mgi)</li> </ul> </li> </ul>"},{"location":"Sources/mgi/#citation","title":"Citation","text":"<p>Blake JA, Baldarelli R, Kadin JA, Richardson JE, Smith CL, Bult CJ; Mouse Genome Database Group. 2021. Mouse Genome Database (MGD): Knowledgebase for mouse-human comparative biology. Nucleic Acids Res. 2021 Jan 8;49(D1):D981-D987.</p>"},{"location":"Sources/ncbi/","title":"National Center for Biotechnology Information (NCBI)","text":"<p>The NCBI Gene integrates information from a wide range of species. A record may include nomenclature, Reference Sequences (RefSeqs), maps, pathways, variations, phenotypes, and links to genome-, phenotype-, and locus-specific resources worldwide.</p> <ul> <li>NCBI bulk downloads</li> </ul>"},{"location":"Sources/ncbi/#gene-information","title":"Gene Information","text":"<p>Genes for all NCBI species (Dog, Cow, Pig, Chicken) are loaded using the ingest file (filtered to only NCBI taxon ID).</p> <p>Biolink Captured</p> <ul> <li>biolink:Gene<ul> <li>id</li> <li>symbol</li> <li>description</li> <li>in_taxon</li> <li>provided_by ([\"infores:ncbi-gene\"])</li> </ul> </li> </ul>"},{"location":"Sources/ncbi/#citation","title":"Citation","text":"<p>National Center for Biotechnology Information (NCBI)[Internet]. Bethesda (MD): National Library of Medicine (US), National Center for Biotechnology Information; [1988] \u2013 [cited 2024 Dec]. Available from: https://www.ncbi.nlm.nih.gov/</p>"},{"location":"Sources/panther/","title":"PANTHER (Protein ANalysis THrough Evolutionary Relationships) Classification System","text":""},{"location":"Sources/panther/#panther-gene-orthology","title":"Panther Gene Orthology","text":"<p>Gene orthology analyses generate testable hypothesis about gene function and biological processes using experimental results from other (especially highly studied so-called 'model' species) using protein (and sometimes, simply nucleic acid level) alignments of genomic sequences.  The source of gene orthology data for this ingest is from the  PANTHER (Protein ANalysis THrough Evolutionary Relationships) Classification System. Panther was designed to classify proteins (and their genes) in order to facilitate high-throughput analysis. Proteins have been classified according to: - Family and subfamily: families are groups of evolutionarily related proteins; subfamilies are related proteins that also have the same function - Molecular function: the function of the protein by itself or with directly interacting proteins at a biochemical level, e.g. a protein kinase - Biological process: the function of the protein in the context of a larger network of proteins that interact to accomplish a process at the level of the cell or organism, e.g. mitosis. - Pathway: similar to biological process, but a pathway also explicitly specifies the relationships between the interacting molecules.</p> <p>The PANTHER Classifications are the result of human curation as well as sophisticated bioinformatics algorithms. Details of the methods can be found in Mi et al. NAR 2013; Thomas et al., Genome Research 2003.</p> <p>This ingest uses data derived form the current version (release 16.0) of the Panther Hidden Markov Model (HMM).</p> <ul> <li>Panther Gene Orthology bulk data downloads</li> </ul> <p>There are various cross-sections of the Panther database which remain be covered by this ingest (Note: T.B.D means \"To Be Done\")</p>"},{"location":"Sources/panther/#status-of-panther-ingest","title":"Status of Panther Ingest","text":"<p>The first iteration of this dataset (committed March 2022) focuses on Reference Genome Gene-to-Gene Orthology Relationships. Additional Panther associations (protein (sub)family pathways, sequences, etc, as generally described below) may be added at a later date.</p>"},{"location":"Sources/panther/#reference-genome-gene-to-gene-orthology-relationships","title":"Reference Genome Gene-to-Gene Orthology Relationships","text":"<p>Contains the Reference Genomes' Gene-to-Gene Ortholog mappings from Panther analyses.</p> <ul> <li>Source File: AllOrthologs.tar.gz. </li> </ul> <p>The source file is huge, containing data from all species, many of which are not currently of direct interest to Monarch. For this reason, a Python function <code>filter_panther_orthologs_file</code> was coded within orthology_utils.</p> <pre><code>ALL_ORTHOLOGS_FILE = \"AllOrthologs\"\nTARGET_SPECIES_ORTHOLOGS = \"TargetOrthologs\"\n\ndef filter_panther_orthologs_file(\n        directory: str = '.',\n        source_filename: str = ALL_ORTHOLOGS_FILE,\n        target_filename: str = TARGET_SPECIES_ORTHOLOGS,\n        number_of_lines: int = 0\n) -&gt; bool:\n    \"\"\"\n    Filters a tar.gz Panther input file against the target list of species.\n    :param directory: str, location of source data file\n    :param source_filename: str, source data file name\n    :param target_filename: str, target data file name\n    :param number_of_lines: int, number of lines parsed; 'all' lines parsed if omitted or set to zero\n    :return: bool, True if filtering was successful; False if unsuccessful\n    \"\"\"\n    ...\n</code></pre> <p>which could be called with default parameter values in the  following manner (if invoked from within the Panther data directory):</p> <pre><code>filter_file()\n</code></pre> <p>to generate a pruned down <code>TargetOrthologs.tar.gz</code> file with target species (as hardcoded in the catalog of species in the ortholog_utils module).</p>"},{"location":"Sources/panther/#panther-data-model-of-panther-orthologs","title":"Panther Data Model of Panther Orthologs","text":"Data Field Content Gene species1 | DB=id1 | protdb=pdbid1 Ortholog species2 | DB=id2 | protdb=pdbid2 Type of ortholog [LDO, O, P, X ,LDX]  see README. Common ancestor for the orthologs taxon name of common ancestor Panther Ortholog ID Panther (sub)family identifier <p>The <code>DB=id#</code> fields - where DB == database namespace and id# is the object identifier - are directly translated, by internal namespace mapping, into gene CURIEs.</p> <p>The <code>species#</code> are abridged labels currently filtered and mapped onto NCBI Taxon identifiers, using an hard-coded dictionary.</p>"},{"location":"Sources/panther/#biolink-classes-and-properties-captured","title":"Biolink classes and properties captured","text":"<ul> <li>biolink:Gene</li> <li>id (NCBIGene Entrez ID)</li> </ul> <p>Note that the Gene <code>source</code> is currently given as Panther, although the real source of a Gene identifier is given by its CURIE namespace.</p> <ul> <li>biolink:GeneToGeneHomologyAssociation</li> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (orthologous to)</li> <li>object (gene.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:panther)</li> </ul>"},{"location":"Sources/panther/#protein-family-and-subfamily-classifications-tbd","title":"Protein Family and Subfamily Classifications - T.B.D.","text":"<p>Contains the PANTHER 16.0 family/subfamily name, with molecular function, biological process, and pathway classifications for every PANTHER protein family and subfamily in the current PANTHER HMM library.</p> <ul> <li> <p>Source File: http://data.pantherdb.org/ftp/hmm_classifications/current_release/PANTHER16.0_HMM_classifications</p> </li> <li> <p>Biolink classes and properties captured:</p> </li> <li> <p>biolink:GeneFamily</p> <ul> <li>id (PANTHER.FAMILY ID)</li> <li>source (infores:panther)</li> </ul> </li> <li> <p>biolink:MolecularActivity</p> <ul> <li>id (GO ID)</li> <li>source (go)</li> </ul> </li> <li> <p>biolink:BiologicalProcess</p> <ul> <li>id (GO ID)</li> <li>source (go)</li> </ul> </li> <li> <p>biolink:Pathway</p> <ul> <li>id (PANTHER.PATHWAY)</li> <li>source (infores:panther)</li> </ul> </li> <li> <p>biolink:GeneFamilyToMolecularFunctionAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene_family.id)</li> <li>predicate (enables)</li> <li>object (go_term.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:panther)</li> </ul> </li> <li> <p>biolink:GeneFamilyToBiologicalProcessAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene_family.id)</li> <li>predicate (involved_in)</li> <li>object (go_term.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:panther)</li> </ul> </li> <li> <p>biolink:GeneFamilyToPathwayAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene_family.id)</li> <li>predicate (involved_in)</li> <li>object (pathway.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:panther)</li> </ul> </li> </ul>"},{"location":"Sources/panther/#pathways-tbd","title":"Pathways - T.B.D.","text":"<p>Contains regulatory and metabolic pathways, each with subfamilies and protein sequences mapped to individual pathway components.</p> <ul> <li> <p>Source File: http://data.pantherdb.org/ftp/pathway/current_release/SequenceAssociationPathway3.6.5.txt   local_name: data/orthology/pathways.tsv</p> </li> <li> <p>Biolink classes and properties captured:</p> <ul> <li>biolink:GeneFamily</li> <li>id (PANTHER.FAMILY ID)</li> <li> <p>source (infores:panther)</p> </li> <li> <p>biolink:Gene</p> </li> <li>id (NCBIGene Entrez ID)</li> <li>in taxon (NCBITaxon ID)</li> <li> <p>source (infores:entrez)</p> </li> <li> <p>biolink:Pathway</p> </li> <li>id (PANTHER.PATHWAY)</li> <li> <p>source (infores:panther)</p> </li> <li> <p>biolink:GeneToPathwayAssociation</p> </li> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (involved_in)</li> <li>object (pathway.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li> <p>primary_knowledge_source (infores:panther)</p> </li> <li> <p>biolink:GeneFamilyToPathwayAssociation</p> </li> <li>id (random uuid)</li> <li>subject (gene_family.id)</li> <li>predicate (involved_in)</li> <li>object (pathway.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:panther)</li> </ul> </li> </ul>"},{"location":"Sources/panther/#sequence-classifications-tbd","title":"Sequence Classifications - T.B.D.","text":"<p>Sequence Classifications files contain the PANTHER family, subfamily, molecular function, biological process, and pathway classifications for the complete proteomes derived from the various genomes, indexed by species (one source file per species).  Refer to the Sequence Classification README for details. </p> <p>Only a subset of the available species will be ingested into Monarch at this time, currently: human, mouse, rat, zebrafish, fruit fly, nematode, fission yeast and budding (\"baker's\") yeast.</p> <ul> <li> <p>Source File Directory: http://data.pantherdb.org/ftp/sequence_classifications/current_release/PANTHER_Sequence_Classification_files/</p> </li> <li> <p>Biolink classes and properties captured:</p> </li> <li> <p>biolink:Gene</p> <ul> <li>id (PANTHER.FAMILY ID)</li> <li>source (infores:panther)</li> </ul> </li> <li> <p>biolink:GeneFamily</p> <ul> <li>id (PANTHER.FAMILY ID)</li> <li>source (infores:panther)</li> </ul> </li> <li> <p>biolink:MolecularActivity</p> <ul> <li>id (GO ID)</li> <li>source (go)</li> </ul> </li> <li> <p>biolink:BiologicalProcess</p> <ul> <li>id (GO ID)</li> <li>source (go)</li> </ul> </li> <li> <p>biolink:Pathway</p> <ul> <li>id (PANTHER.PATHWAY)</li> <li>source (infores:panther)</li> </ul> </li> <li> <p>biolink:GeneToGeneFamilyAssociation:</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (member_of)</li> <li>object (gene_family.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:panther)</li> </ul> </li> <li> <p>biolink:MacromolecularMachineToMolecularActivityAssociation:</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (enables)</li> <li>object (go_term.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:panther)</li> </ul> </li> <li> <p>biolink:MacromolecularMachineToBiologicalProcessAssociation:</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (involved_in)</li> <li>object (go_term.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:panther)</li> </ul> </li> <li> <p>biolink:GeneToPathwayAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (involved_in)</li> <li>object (pathway.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:panther)</li> </ul> </li> </ul>"},{"location":"Sources/panther/#citation","title":"Citation","text":"<p>Paul D. Thomas, Dustin Ebert, Anushya Muruganujan, Tremayne Mushayahama, Laurent-Philippe Albou and Huaiyu Mi Protein Society. 2022;31(1):8-22. doi:10.1002/pro.4218</p>"},{"location":"Sources/phenio/","title":"PHENIO","text":"<p>PHENIO is an ontology for accessing and comparing knowledge concerning phenotypes across species and genetic backgrounds.</p> <p>Phenio provides the \"semantic backbone\" of the Monarch Knowledge Graph. Designed as an application ontology, PHENIO integrates a variety of ontological concepts, in particular the \"core entities\" in the Monarch Knowledge Graph (KG), including diseases, phenotypes and anatomical entities.</p> <p>Note that while forming an integral part of the Monarch KG, PHENIO does not have a \"Koza Ingest\" configuration like all the other sources,  but is instead ingested into Monarch KG straight via a <code>OWL -&gt; obographs -&gt; KGX</code> transform.</p>"},{"location":"Sources/phenio/#sources","title":"Sources","text":"<p>PHENIO integrates several different types of hierarchical relationships from a variety of sources.</p> <p>These include: * Chemical entities and relationships from CHEBI * Disease entities and relationships from MONDO * Abnormal phenotypes of humans (HPO), mouse and other mammalian species (MPO), the nematode worm Caenorhabditis elegans (WBBT), and zebrafish (ZFA).</p> <p>A full list of files used in the construction of PHENIO is available here.</p>"},{"location":"Sources/phenio/#more-information","title":"More Information","text":"<p>For more information, see:</p> <ul> <li>NCATS Translater Phenio Overview</li> <li>KGHub Phenio </li> <li>Monarch Phenio</li> <li>Documentation</li> </ul>"},{"location":"Sources/phenio/#source-code","title":"Source Code","text":"<p>https://github.com/monarch-initiative/phenio</p>"},{"location":"Sources/pombase/","title":"PomBase","text":"<p>PomBase is a comprehensive database for the fission yeast Schizosaccharomyces pombe, providing structural and functional annotation, literature curation and access to large-scale data sets. Within this ingest there will be a transformation of gene to phenotypic feature associations, gene entities aren't yet loaded as a part of this ingest, and FYPO ontology terms will be brought in directly from the ontology without transformation.</p> <ul> <li>PomBase Bulk Downloads</li> <li>Phaf Format Description</li> <li>Phaf Format LinkML</li> </ul>"},{"location":"Sources/pombase/#gene-information","title":"Gene Information","text":"<p>PomBase genes are captured directly from the PomBase (names and identifiers)[https://www.pombase.org/downloads/names-and-identifiers] set, with synonyms being populated as available and UniProtKB accessions captured as xrefs if available.   </p> <p>Biolink Captured</p> <ul> <li>biolink:Gene</li> <li>id</li> <li>symbol</li> <li>xref (UniProfKB curie if provided)</li> <li>synonym</li> <li>provided_by([\"infores:pombase\"])</li> </ul>"},{"location":"Sources/pombase/#gene-to-phenotype","title":"Gene to Phenotype","text":"<p>The PHAF download file is extremely well documented. Alleles provided, but not captured, with the assumption that even with an allele specified the gene to phenotype is accurate with a some-some interpretation. Genotype/strain information looks uniform throughout the file, and is not captured. It might be sensible to make presence of genotype information an error condition to be sure that we only get 'clean' gene to phenotype associations.  </p> <p>Penetrance and Severity columns are available, but not captured as a part of this ingest. Penetrance values can be either FYPO_EXT terms (FYPO_EXT:0000001, FYPO_EXT:0000002, FYPO_EXT:0000003, FYPO_EXT:0000004), int/float numbers (percentages), or strings (\"&gt;98\", \"~10\", \"10-20\"). Severity is represented using one or more FYPO_EXT terms.</p> <p>Biolink Captured</p> <ul> <li> <p>biolink:Gene</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:PhenotypicFeature</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:GeneToPhenotypicFeatureAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (has_phenotype)</li> <li>object (phenotypicFeature.id)</li> <li>publications</li> <li>qualifiers (optionally included from condition row)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:pombase)</li> </ul> </li> </ul>"},{"location":"Sources/pombase/#citation","title":"Citation","text":"<p>\"Harris MA, Rutherford KM, Hayles J, Lock A, B\u00e4hler J, Oliver S, Mata J, Wood V Fission stories: Using PomBase to understand Schizosaccharomyces pombe biology Genetics, 2021; iyab222\"</p>"},{"location":"Sources/reactome/","title":"Reactome","text":"<p>Reactome is a free, open-source, curated and peer reviewed pathway database. Our goal is to provide intuitive bioinformatics tools for the visualization, interpretation and analysis of pathway knowledge to support basic research, genome analysis, modeling, systems biology and education.</p> <ul> <li>Reactome bulk downloads</li> </ul>"},{"location":"Sources/reactome/#pathway","title":"Pathway","text":"<p>This ingest uses Reactome's pathway download file. </p> <p>Biolink captured</p> <ul> <li>biolink:Pathway<ul> <li>id</li> <li>name</li> <li>in_taxon</li> <li>provided_by ([\"infores:reactome\"])</li> </ul> </li> </ul>"},{"location":"Sources/reactome/#gene-to-pathway","title":"Gene to Pathway","text":"<p>This ingest uses Reactome's gene to pathway download file, which contains all entities and only assocations between pathways and genes that are denoted in some way in the pathyways. </p> <p>Biolink captured</p> <ul> <li> <p>biolink:Gene</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:Pathway</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:ChemicalToPathwayAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (mentions)</li> <li>object (pathway.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:reactome)</li> </ul> </li> </ul>"},{"location":"Sources/reactome/#chemical-to-pathway","title":"Chemical to Pathway","text":"<p>This ingest uses Reactome's chemical to pathway download file, which contains all entities and only assocations between pathways and chemicals that are denoted in some way in the pathyways. </p> <p>Biolink captured</p> <ul> <li> <p>biolink:ChemicalEntity</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:Pathway</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:ChemicalToPathwayAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (chemical.id)</li> <li>predicate (mentions)</li> <li>object (pathway.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:reactome)</li> </ul> </li> </ul>"},{"location":"Sources/reactome/#citation","title":"Citation","text":"<p>Marc Gillespie, Bijay Jassal, Ralf Stephan, Marija Milacic, Karen Rothfels, Andrea Senff-Ribeiro, Johannes Griss, Cristoffer Sevilla, Lisa Matthews, Chuqiao Gong, Chuan Deng, Thawfeek Varusai, Eliot Ragueneau, Yusra Haider, Bruce May, Veronica Shamovsky, Joel Weiser, Timothy Brunson, Nasim Sanati, Liam Beckman, Xiang Shao, Antonio Fabregat, Konstantinos Sidiropoulos, Julieth Murillo, Guilherme Viteri, Justin Cook, Solomon Shorser, Gary Bader, Emek Demir, Chris Sander, Robin Haw, Guanming Wu, Lincoln Stein, Henning Hermjakob, Peter D\u2019Eustachio, The reactome pathway knowledgebase 2022, Nucleic Acids Research, Volume 50, Issue D1, 7 January 2022, Pages D687\u2013D692, https://doi.org/10.1093/nar/gkab1028</p>"},{"location":"Sources/rgd/","title":"Rat Genome Database (RGD)","text":"<p>The Rat Genome Database (RGD) was established in 1999 and is the premier site for genetic, genomic, phenotype, and disease data generated from rat research. In addition, it provides easy access to corresponding human and mouse data for cross-species comparisons.</p> <ul> <li>RGD bulk downloads</li> </ul>"},{"location":"Sources/rgd/#gene-literature","title":"Gene Literature","text":"<p>This ingest uses RGD's gene file which contains publication assocations that are denoted in some way in the publication. We have selected to use a consistent high level term for 'publication' (IAO:0000311) as it is heterogeneous mix of publication types being referenced. Even though it is a gene file, and we have fully populated the gene nodes in the alliance gene information ingest, the RGD file has some information that is not in alliance.</p> <p>Note, there will be a column mismatch warning on this transform because there are two (UNUSED) columns.</p> <p>Biolink captured</p> <ul> <li> <p>biolink:Gene</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:Publication</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:InformationContentEntityToNamedThingAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (mentions)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:rgd)</li> </ul> </li> </ul>"},{"location":"Sources/rgd/#citation","title":"Citation","text":"<p>Vedi M, Smith JR, Thomas Hayman G, Tutaj M, Brodie KC, De Pons JL, Demos WM, Gibson AC, Kaldunski ML, Lamers L, Laulederkind SJF, Thota J, Thorat K, Tutaj MA, Wang SJ, Zacher S, Dwinell MR, Kwitek AE. 2022 updates to the Rat Genome Database: a Findable, Accessible, Interoperable, and Reusable (FAIR) resource. Genetics. 2023 May 4;224(1):iyad042. doi: 10.1093/genetics/iyad042. PMID: 36930729; PMCID: PMC10474928.</p>"},{"location":"Sources/sgd/","title":"Saccharomyces Genome Database (SGD)","text":"<p>The Saccharomyces Genome Database (SGD) provides comprehensive integrated biological information for the budding yeast Saccharomyces cerevisiae along with search and analysis tools to explore these data, enabling the discovery of functional relationships between sequence and gene products in fungi and higher organisms.</p> <ul> <li>SGD bulk downloads</li> </ul>"},{"location":"Sources/sgd/#gene-literature","title":"Gene Literature","text":"<p>This ingest uses RGD's gene to publication download file, which only contains assocations between publications and genes that are denoted in some way in the publication. We have selected to use a consistent high level term for 'publication' (IAO:0000311) as it is heterogeneous mix of publication types being referenced. </p> <p>Biolink captured</p> <ul> <li> <p>biolink:Gene</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:Publication</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:InformationContentEntityToNamedThingAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (mentions)</li> <li>object (publication.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:sgd)</li> </ul> </li> </ul>"},{"location":"Sources/sgd/#citation","title":"Citation","text":"<p>Cherry JM, Hong EL, Amundsen C, Balakrishnan R, Binkley G, Chan ET, Christie KR, Costanzo MC, Dwight SS, Engel SR, Fisk DG, Hirschman JE, Hitz BC, Karra K, Krieger CJ, Miyasato SR, Nash RS, Park J, Skrzypek MS, Simison M, Weng S, Wong ED (2012) Saccharomyces Genome Database: the genomics resource of budding yeast. Nucleic Acids Res. Jan;40(Database issue):D700-5. [PMID: 22110037]</p>"},{"location":"Sources/string/","title":"STRING: functional protein association networks","text":"<p>STRING is a database of known and predicted protein-protein interactions. The interactions include direct (physical) and indirect (functional) associations; they stem from computational prediction, from knowledge transfer between organisms, and from interactions aggregated from other (primary) databases.</p> <ul> <li>STRING bulk downloads</li> </ul>"},{"location":"Sources/string/#protein-links","title":"Protein Links","text":"<p>This ingest uses a given version (currently, 11.5) of the STRING's .protein.links.detailed..txt.gz files, for a subset of NCBI  ID designated species. We filter the input data on the combined_score field (currently with the threshhold recorded in the protein_links.yaml file). The various taxon specific entrez_2_string mapping files are used to map protein subject and concept nodes onto Entrez gene id's."},{"location":"Sources/string/#special-note-about-entrez-mapping-files","title":"Special note about Entrez mapping files","text":"<p>A separate Entrez to String identifier mapping file is not available for Rattus norvegicus (Norway rat, NCBI taxon ID 10116) but the mappings are (less conveniently) available inside the aggregated 'all_organisms' entrez_2_string file. See notes in the STRING section of the download.yaml configuration file for (self explanatory) guidance on how to prepare the required mapping file for use in a local running of the digest.</p>"},{"location":"Sources/string/#source-file","title":"Source File","text":"<ul> <li>protein1</li> <li>protein2</li> <li>neighborhood</li> <li>fusion</li> <li>cooccurence</li> <li>coexpression</li> <li>experimental</li> <li>database</li> <li>textmining</li> <li>combined_score</li> </ul>"},{"location":"Sources/string/#biolink-classes-and-properties-captured","title":"Biolink classes and properties captured","text":""},{"location":"Sources/string/#concept-nodes","title":"Concept Nodes","text":"<ul> <li>biolink:Gene</li> <li>id (NCBIGene Entrez ID)</li> </ul>"},{"location":"Sources/string/#associations","title":"Associations","text":"<ul> <li>biolink:PairwiseGeneToGeneInteraction:<ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (interacts_with)</li> <li>object (gene.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:string)</li> </ul> </li> </ul>"},{"location":"Sources/string/#citation","title":"Citation","text":"<p>Damian Szklarczyk, Andrea Franceschini, Stefan Wyder, Kristoffer Forslund, Davide Heller, Jaime Huerta-Cepas, Milan Simonovic, Alexander Roth, Alberto Santos, Kalliopi P. Tsafou, Michael Kuhn, Peer Bork, Lars J. Jensen, Christian von Mering, STRING v10: protein\u2013protein interaction networks, integrated over the tree of life, Nucleic Acids Research, Volume 43, Issue D1, 28 January 2015, Pages D447\u2013D452, https://doi.org/10.1093/nar/gku1003</p>"},{"location":"Sources/xenbase/","title":"Xenbase","text":"<p>Xenbase is a web-accessible resource that integrates all the diverse biological, genomic, genotype and phenotype data available from Xenopus research.</p> <p>Xenbase Bulk Data Xenbase FTP</p>"},{"location":"Sources/xenbase/#gene-to-phenotype","title":"Gene to Phenotype","text":"<p>This ingest is built against a one-off OBAN formatted file, which makes for a transformation which only requries adding a curie prefix and connecting column names to biolink attributes. Evidence codes are provided as ECO terms but not yet captured in the output. </p> <p>Biolink captured</p> <ul> <li> <p>biolink:Gene</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:PhenotypicFeature</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:GeneToPhenotypicFeatureAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (has_phenotype)</li> <li>object (phenotypicFeature.id)</li> <li>publications</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:xenbase)</li> </ul> </li> </ul>"},{"location":"Sources/xenbase/#gene-literature","title":"Gene Literature","text":"<p>This ingest reads from Xenbase's Genes Associated with Literature file to capture associations between Xenbase's XB-GENEPAGE ids and PMIDs, then relies on a map built from Xenbase's GenepageToGeneId file to create associations from XB-GENE records to PMID records.</p> <p>Biolink captured</p> <ul> <li> <p>Gene</p> <ul> <li>id</li> </ul> </li> <li> <p>Publication</p> <ul> <li>id</li> </ul> </li> <li> <p>InformationContentEntityToNamedThingAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (mentions)</li> <li>object (publication.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:xenbase)</li> </ul> </li> </ul>"},{"location":"Sources/xenbase/#citation","title":"Citation","text":"<p>Fisher et al. 2023, Genetics, 2023;, iyad018, doi:10.1093/genetics/iyad018 (Xenbase / PubMed / Genetics)</p>"},{"location":"Sources/zfin/","title":"ZFIN","text":"<p>ZFIN is the Zebrafish Model Organism Database. </p> <ul> <li>ZFIN bulk downloads</li> </ul>"},{"location":"Sources/zfin/#gene-to-phenotype","title":"Gene to Phenotype","text":"<p>This ingest uses ZFIN's clean gene phenotype download file, which only contains phenotypes which can safely be associated to a single affected gene. This ingest is distinct from the Alliance phenotype index because ZFIN builds Entity-Quality-Entity phenotype statements that can be built from post-composed terms (E1a+E1b+Q+E2a+E2b), </p> <p>Biolink captured</p> <ul> <li> <p>biolink:Gene</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:PhenotypicFeature</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:GeneToPhenotypicFeatureAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (has_phenotype)</li> <li>object (phenotypicFeature.id)</li> <li>publications</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:zfin)</li> </ul> </li> </ul>"},{"location":"Sources/zfin/#gene-literature","title":"Gene Literature","text":"<p>This ingest uses ZFIN's gene to publication download file, which only contains assocations between publications and genes that are denoted in some way in the publication. We have selected to use a consistent high level term for 'publication' (IAO:0000311) as it is heterogeneous mix of publication types being referenced. We have also opted to use the ZDB-ID for the publication node rather than a pubmed ID, on the assumption that kgx will clique merge them later.</p> <p>Biolink captured</p> <ul> <li> <p>biolink:Gene</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:Publication</p> <ul> <li>id</li> </ul> </li> <li> <p>biolink:InformationContentEntityToNamedThingAssociation</p> <ul> <li>id (random uuid)</li> <li>subject (gene.id)</li> <li>predicate (mentions)</li> <li>object (publication.id)</li> <li>aggregating_knowledge_source ([\"infores:monarchinitiative\"])</li> <li>primary_knowledge_source (infores:zfin)</li> </ul> </li> </ul>"},{"location":"Sources/zfin/#citation","title":"Citation","text":"<p>Bradford, Y.M., Van Slyke, C.E., Ruzicka, L., Singer, A., Eagle, A., Fashena, D., Howe, D.G., Frazer, K., Martin, R., Paddock, H., Pich, C., Ramachandran, S., Westerfield, M. (2022) Zebrafish Information Network, the knowledgebase for Danio rerio research. Genetics. 220(4).</p>"}]}